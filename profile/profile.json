{
  "education": [
    {
      "awards_achievements": [
        "GPA: 3.6/4.0"
      ],
      "degree": "Master of Computer Application",
      "department": "Computer Application",
      "duration": "2008-2011",
      "school_name": "University of Pune, India"
    }
  ],
  "github_repo_root_url": "https://github.com/jarviscanada/jarvis_data_eng_SnehalGalande",
  "highlighted_projects": [
    {
      "description": "Suspendisse a tincidunt odio. Suspendisse posuere luctus aliquet. Quisque magna tellus, tempor vitae arcu sed, volutpat scelerisque lacus. Aliquam varius pulvinar dapibus. Ut a tincidunt sem. Aenean sollicitudin fringilla erat ut imperdiet. Phasellus fermentum, enim vitae laoreet elementum, eros nisl hendrerit lorem.",
      "git_url": "https://github.com/jarviscanada/jarvis_profile_builder",
      "name": "Web app for resturant"
    },
    {
      "description": "Suspendisse a tincidunt odio. Suspendisse posuere luctus aliquet. Quisque magna tellus, tempor vitae arcu sed, volutpat scelerisque lacus. Aliquam varius pulvinar dapibus. Ut a tincidunt sem. Aenean sollicitudin fringilla erat ut imperdiet. Phasellus fermentum, enim vitae laoreet elementum, eros nisl hendrerit lorem.",
      "git_url": null,
      "name": "Machine Learning"
    }
  ],
  "jarvis_projects": [
    {
      "description": "Implemented Linux Cluster Monitoring Agent tool that manages a CentOS7 cluster comprising 10 nodes interconnected via a switch. The tool records hardware specifications and monitors real-time resource usage, like CPU and memory, across nodes for generating future resource planning reports. Utilizing Bash, it automates tasks using crontab scheduler which runs the scripts on node computers every minute and gets the usage data. PostgreSQL (psql) handles database management and querying, Git tracks source code changes for version control, and Docker ensures efficient containerization.",
      "git_url": "/linux_sql",
      "name": "Linux Cluster Resource Monitoring App"
    }
  ],
  "name": "Snehal Galande",
  "others": [
    {
      "bullets": [
        "1Z0-047 Oracle Database SQL Expert(2012)"
      ],
      "title": "Certificates"
    },
    {
      "bullets": [
        "I shuttlecock around on the badminton court, and also enjoy cycling.",
        "Loves to go on Sandy vacations"
      ],
      "title": "Activities/Hobbies"
    }
  ],
  "professional_experience": [
    {
      "company": "Jarvis",
      "description": "Developed multiple projects such Cluster Monitor which was developed on Linux platform that records hardware specifications and monitors real-time resource usage, like CPU and memory, across nodes for generating future resource planning reports. This project also employed SQL for database management, GIT for version control, and followed SDLC methodologies. Improved and strengthened my soft skills to to become more confident, capable, and better at leading.",
      "duration": "2024-present",
      "title": "Software Developer"
    },
    {
      "company": "Nitor Infotech Pvt. Ltd.",
      "description": "Client is a digital marketing firm, developing programs for different firms. The system simplifies day to day operations of an ETL which enables to load the data in Data warehouse. Developed packages for loading data involving sources such as SQL database, Excel and flat files, Search engine APIs like Google/MSN, Jason data etc as well as enhanced existing packages with new requirements or defect fixing. Deployed code to different environments using SSIS DB catlog from SSMS. Performed SQL development tasks which included creating stored procedures, utilizing local/global temporary tables, ranking functions, indexes, and joins. Created and scheduled SQL Agent jobs in SSMS. Source code version control was managed using TFS. Developed Visual reports and dashboards in Power BI, with a focus on data modeling and maintaining relationship. Implemented filters, data slicing, and created DAX queries to extract meaningful insights from the data. This enhanced data visualization and analysis, enabling informed decision-making within the organization.",
      "duration": "2014-2017",
      "title": "Leapfrog Online Inc"
    },
    {
      "company": "Nitor Infotech Pvt. Ltd.",
      "description": "Created TALEND mappings using various processing and orchestration components, features such as context variables, connectors for Database and flat files, and File components, Joblets, reusable components like routines, context variable and globalMap variables. Monitored and supported the Talend jobs scheduled through Talend Admin Center (TAC). For Tableau 9.1, developed various dashboards using different sources, used context filters, sets while dealing with huge volume of data. Generated Dashboards by joining tables and used dual axis for comparison, filters, quick filters, sets, parameters and calculated fields.",
      "duration": "2014-2015",
      "title": "Healthcare firm"
    },
    {
      "company": "Nitor Infotech Pvt. Ltd.",
      "description": "RidePoolr is a website and application for ride-sharing/car-pooling targeted for US market. RidePoolr allows you to match up with like-minded individuals to share a ride together to an event, like Burning Man, etc. thereby providing the user to smoothly share a vehicle, and thus reducing emissions due to travel. The user can create, view, share and accept requests for rides from other individuals. It provides a deep integration with commonly used social networking sites and Google Maps.",
      "duration": "2013-2014",
      "title": "RidePoolr"
    }
  ],
  "skills": {
    "competent": [
      "Java",
      "Linux/Bash",
      "RDBMS/SQL",
      "Agile/Scrum",
      "Git"
    ],
    "familiar": [
      "Java",
      "Linux/Bash",
      "RDBMS/SQL",
      "Agile/Scrum",
      "Git"
    ],
    "proficient": [
      "Microsoft Power BI Desktop",
      "Data query language/SQL",
      "DAX",
      "Spark using Python",
      "Azure Databricks",
      "GIT",
      "Linux"
    ]
  },
  "summary": "I have completed Masters Degree in Computer Applications and I have 3 yrs of experience in data engineering and analysis. I have worked as Business Intelligence Analyst with a passion for turning raw data into actionable and meaningful insights. I have Hands-on experience of building data integration pipelines using ETL process. I have good experience with data analysis, visualization, and reporting to empower organizations in making informed decisions."
}
